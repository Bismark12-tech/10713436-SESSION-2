{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f462ad6",
   "metadata": {},
   "source": [
    "# CSCD 319 - COMPUTER VISION\n",
    "\n",
    "## LAB SESSION 2: \n",
    "### TOPIC:    Introduction to Convolutional Neural Networks (CNN) and MobileNet using Keras with Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889dc984",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e24109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STUFF ARE ON COLAB, THAT IS ONLINE \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce73c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries that will be needed to carry out the tasks\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1538bc",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The images included in the data directory are a random subset of the full cat and dog data set from the following Kaggle competition: https://www.kaggle.com/c/dogs-vs-cats/data \n",
    "\n",
    "The dataset contains 25,000 images of dogs and cats.\n",
    "\n",
    "After downloading the dataset, you will get a zip file that contains a sampleSubmission file, a test.zip file and a train.zip file. You may delete the sampleSubmission file and the test.zip file as they will be irrelevant for our session. Ensure that your Notebook and the data files are not in the same directory as commiting to GitHub will send the images to your repository as well, which is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4f1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Organize data into train, valid, test dirs\n",
    "# # os.chdir('../data/dogs-vs-cats')\n",
    "# if os.path.isdir('train/dog') is False:\n",
    "#     os.makedirs('train/dog')\n",
    "#     os.makedirs('train/cat')\n",
    "#     os.makedirs('valid/dog')\n",
    "#     os.makedirs('valid/cat')\n",
    "#     os.makedirs('test/dog')\n",
    "#     os.makedirs('test/cat')\n",
    "\n",
    "#     for i in random.sample(glob.glob('cat*'), 500):\n",
    "#         shutil.move(i, 'train/cat')      \n",
    "#     for i in random.sample(glob.glob('dog*'), 500):\n",
    "#         shutil.move(i, 'train/dog')\n",
    "#     for i in random.sample(glob.glob('cat*'), 100):\n",
    "#         shutil.move(i, 'valid/cat')        \n",
    "#     for i in random.sample(glob.glob('dog*'), 100):\n",
    "#         shutil.move(i, 'valid/dog')\n",
    "#     for i in random.sample(glob.glob('cat*'), 50):\n",
    "#         shutil.move(i, 'test/cat')      \n",
    "#     for i in random.sample(glob.glob('dog*'), 50):\n",
    "#         shutil.move(i, 'test/dog')\n",
    "\n",
    "# os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up paths for data files.\n",
    "\n",
    "train_path = 'data/dogs-vs-cats/train'\n",
    "valid_path = 'data/dogs-vs-cats/valid'\n",
    "test_path = 'data/dogs-vs-cats/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to put the data in a format that the model understands.\n",
    "# In keras, we do so with the ImageGenerator() method.\n",
    "# This will create batches of data from the directory where the datasets resides\n",
    "# And these batches of data will be passed to the sequential model\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['cat','dog'], batch_size=10)\n",
    "\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['cat','dog'], batch_size=10)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['cat','dog'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the number of classes and images for our train, valid and test sets\n",
    "assert train_batches.n == 1000\n",
    "assert valid_batches.n == 200\n",
    "assert test_batches.n == 100\n",
    "assert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6464f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the indices of each label\n",
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c43de245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of images from a particular batch\n",
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da10139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 10 columns where images are place\n",
    "# Function taken directly from Tensorflow website\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting images from the 'imgs' batches along their labels\n",
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26a496",
   "metadata": {},
   "source": [
    "### Build and train a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa27719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the keras sequential model to build our model\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(224,224,3)),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc6a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 401410    \n",
      "=================================================================\n",
      "Total params: 420,802\n",
      "Trainable params: 420,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check out a summary of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61db1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of trainable parameters in a model\n",
    "model1 = Sequential([\n",
    "    Dense(3, input_shape=(2,),activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2fd8c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 17\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43d5f475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.19172215,  0.62808645,  0.07934272],\n",
       "        [-0.2104531 ,  0.11328602, -0.6208496 ]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.7409272 ,  0.90590715],\n",
       "        [ 0.9642317 , -0.99728036],\n",
       "        [-0.16808617,  0.6581315 ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the model for training\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now train our model\n",
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76bc60a",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1008c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data from the test images and then plot that batch\n",
    "test_imgs, test_labels = next(test_batches)\n",
    "plotImages(test_imgs)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a70beb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unshuffled test set\n",
    "test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a prediction on the test set\n",
    "predictions = model.predict(x=test_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding the probabilities to zero and one\n",
    "np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ced08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a confusion matrix to view the performance of the model on the test set\n",
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a425c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a confusion Matrix\n",
    "# Directly copied from the Scikit Learn website\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                         normalize=False,\n",
    "                         title='Confusion matrix',\n",
    "                         cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting 'normalize=True'.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the indices of each label\n",
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0de810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the labels of the confusion Matrix and plotting it\n",
    "cm_plot_labels = ['cat', 'dog']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2a1e8",
   "metadata": {},
   "source": [
    "### ASSIGNMENT 1 - 3 marks\n",
    "\n",
    "#### Improving model performance.\n",
    "\n",
    "Tune the parameters of the Convolutional Neural Network above to achieve a better performance comparative to what was achieved in class.\\\n",
    "The sum of the True Positive value and that of the True Negative value should be greater than or equal to 70% of the total number of files in the test dataset.\n",
    "\n",
    "You may achieve this through the following ways.\n",
    "1. You may include more of the data files when training your model.\n",
    "2. You may try out other types of optimizers.\n",
    "3. You may change the learning rate.\n",
    "4. You may add more layers to the Sequential model\n",
    "5. Etc.\n",
    "\n",
    "Use the resulting confusion matrix to determine the performance of your tuned model. \n",
    "\n",
    "#### DEADLINE: \n",
    "Sunday, April 2nd, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ccde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to put the data in a format that the model understands.\n",
    "# In keras, we do so with the ImageGenerator() method.\n",
    "# This will create batches of data from the directory where the datasets resides\n",
    "# And these batches of data will be passed to the sequential model\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['cat','dog'], batch_size=10)\n",
    "\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['cat','dog'], batch_size=10)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['cat','dog'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d487e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the number of classes and images for our train, valid and test sets\n",
    "assert train_batches.n == 1000\n",
    "assert valid_batches.n == 200\n",
    "assert test_batches.n == 100\n",
    "assert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89648b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the indices of each label\n",
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164726e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Overview of images from a particular batch\n",
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda401f",
   "metadata": {},
   "source": [
    "## MobileNet With Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8925d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43258f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to make sure that Tensorflow can identify your GPU if you are using a GPU\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#print(\"Num GPUs Available: \", len(physical_devices))\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75943467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading MobileNet Model\n",
    "mobile = tf.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e26ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a function to preprocess the Images with MobileNet Preprocessing function\n",
    "def prepare_image(file):\n",
    "    img_path = 'data/MobileNet-samples/'\n",
    "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first image in the data set\n",
    "from IPython.display import Image\n",
    "Image(filename='data/MobileNet-samples/1.jpg', width=300, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb12db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess the image and display the possible predictions for the image (mostly the top 5 predictions)\n",
    "preprocessed_image = prepare_image('1.jpg')\n",
    "predictions = mobile.predict(preprocessed_image)\n",
    "results = imagenet_utils.decode_predictions(predictions)  #Top five predictions from the 1000 possible ImageNet classes\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6b026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image and display the possible predictions for the image (mostly the top 5 predictions)\n",
    "preprocessed_image = prepare_image('2.jpg')\n",
    "predictions = mobile.predict(preprocessed_image)\n",
    "results = imagenet_utils.decode_predictions(predictions)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd62010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aae62e8d",
   "metadata": {},
   "source": [
    "### ASSIGNMENT 2 - 2 marks\n",
    "\n",
    "Download two different random images online and do the following:\n",
    "\n",
    "1. View the image in your Notebook.\n",
    "2. Preprocess the image and display the possible predictions for the image (the top 5 predictions) with the MobileNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235bba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3241a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading MobileNet Model\n",
    "mobile = tf.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a function to preprocess the Images with MobileNet Preprocessing function\n",
    "def prepare_image(file):\n",
    "    img_path = ''\n",
    "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80db6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first image in the data set\n",
    "from IPython.display import Image\n",
    "Image(filename='1.jpg', width=300, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image and display the possible predictions for the image (mostly the top 5 predictions)\n",
    "preprocessed_image = prepare_image('1.jpg')\n",
    "predictions = mobile.predict(preprocessed_image)\n",
    "results = imagenet_utils.decode_predictions(predictions)  #Top five predictions from the 1000 possible ImageNet classes\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image and display the possible predictions for the image (mostly the top 5 predictions)\n",
    "preprocessed_image = prepare_image('2.JPG')\n",
    "predictions = mobile.predict(preprocessed_image)\n",
    "results = imagenet_utils.decode_predictions(predictions)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
